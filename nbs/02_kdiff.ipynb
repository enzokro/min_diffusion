{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core \n",
    "\n",
    "> Minimal pipeline for Diffusion Guidance experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp kdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# imports for diffusion models\n",
    "from abc import ABC\n",
    "import importlib\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm    import tqdm\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from diffusers    import AutoencoderKL, UNet2DConditionModel\n",
    "from diffusers    import LMSDiscreteScheduler, EulerDiscreteScheduler, DPMSolverMultistepScheduler, EulerAncestralDiscreteScheduler\n",
    "import torch\n",
    "from torch import nn\n",
    "from min_diffusion import utils\n",
    "try:\n",
    "    from k_diffusion.external import CompVisDenoiser, CompVisVDenoiser\n",
    "    from k_diffusion.sampling import get_sigmas_karras\n",
    "    import k_diffusion.sampling as k_sampling\n",
    "except:\n",
    "    print(f'WARNING: Could not import k_diffusion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class ImageSampler(ABC):\n",
    "    short_name: str\n",
    "    name: str\n",
    "    default_steps: int\n",
    "    default_size: int\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.device = utils.get_device()\n",
    "        \n",
    "        \n",
    "class ModelWrapper:\n",
    "    def __init__(self, model, alphas_cumprod):\n",
    "        self.model = model\n",
    "        self.alphas_cumprod = alphas_cumprod\n",
    "\n",
    "    def apply_model(self, *args, **kwargs):\n",
    "        return self.model(*args, **kwargs).sample\n",
    "        \n",
    "        \n",
    "class WrappedCompVisDenoiser(CompVisDenoiser):\n",
    "    \"\"\"Short wrapping for more general calls to `apply_model`.\n",
    "    \"\"\"\n",
    "    def apply_model(self, *args, **kwargs):\n",
    "        return self.inner_model.apply_model(*args, **kwargs)\n",
    "\n",
    "\n",
    "class WrappedCompVisVDenoiser(CompVisVDenoiser):\n",
    "    \"\"\"Short wrapping for more general calls to `apply_model`.\n",
    "    \"\"\"\n",
    "    def apply_model(self, *args, **kwargs):\n",
    "        return self.inner_model.apply_model(*args, **kwargs)\n",
    "\n",
    "    \n",
    "\n",
    "class KDiffusionNames:\n",
    "    # PLMS = \"plms\"\n",
    "    # DDIM = \"ddim\"\n",
    "    K_DPM_FAST           = \"k_dpm_fast\"\n",
    "    K_DPM_ADAPTIVE       = \"k_dpm_adaptive\"\n",
    "    K_LMS                = \"k_lms\" \n",
    "    K_DPM_2              = \"k_dpm_2\"\n",
    "    K_DPM_2_ANCESTRAL    = \"k_dpm_2_a\"\n",
    "    K_DPMPP_2M           = \"k_dpmpp_2m\"\n",
    "    K_DPMPP_2S_ANCESTRAL = \"k_dpmpp_2s_a\"\n",
    "    K_EULER              = \"k_euler\"\n",
    "    K_EULER_ANCESTRAL    = \"k_euler_a\"\n",
    "    K_HEUN               = \"k_heun\"\n",
    "    K_DPMPP_SDE          = 'k_dpmpp_sde'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFG Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class CFGDenoiser(nn.Module):\n",
    "    \"\"\"Runs Classifier-free Guidance with optional schedules and normalizations.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, guide_tfm=None):\n",
    "        super().__init__()\n",
    "        self.inner_model = model\n",
    "        self.guide_tfm = guide_tfm\n",
    "        self.device = utils.get_device()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        sigma,\n",
    "        uncond,\n",
    "        cond,\n",
    "        mask=None,\n",
    "        mask_noise=None,\n",
    "        orig_latent=None,\n",
    "        g_idxs=None,\n",
    "    ):\n",
    "        def _wrapper(noisy_latent_in, time_encoding_in, conditioning_in):\n",
    "            return self.inner_model(\n",
    "                noisy_latent_in, time_encoding_in, cond=conditioning_in\n",
    "            )\n",
    "\n",
    "        noise_pred = self.get_noise_prediction(\n",
    "            denoise_func=_wrapper,\n",
    "            noisy_latent=x,\n",
    "            time_encoding=sigma,\n",
    "            uncond=uncond,\n",
    "            cond=cond,\n",
    "            g_idxs=g_idxs,\n",
    "        )\n",
    "        return noise_pred\n",
    "    \n",
    "    def get_noise_prediction(\n",
    "        self,\n",
    "        denoise_func,\n",
    "        noisy_latent,\n",
    "        time_encoding,\n",
    "        uncond,\n",
    "        cond,\n",
    "        g_idxs,\n",
    "    ):\n",
    "        # pad the latent with batch dimensions if needed\n",
    "        noisy_latent = utils.maybe_add_batch_dim(noisy_latent)\n",
    "        \n",
    "        # prepare the noisy latents for conditional and unconditional inputs\n",
    "        noisy_latent_in = torch.cat([noisy_latent] * 2)\n",
    "        time_encoding_in = torch.cat([time_encoding] * 2)\n",
    "\n",
    "        # prepare the unconditional and conditional prompts\n",
    "        text_embeds = torch.cat([uncond, cond])\n",
    "\n",
    "        # the k-diffusion samplers actually return the denoised predicted latents but things seem\n",
    "        # to work anyway\n",
    "        noise_pred_neutral, noise_pred_positive = denoise_func(\n",
    "            noisy_latent_in, time_encoding_in, text_embeds\n",
    "        ).chunk(2)\n",
    "    \n",
    "        # run the guidance scheduler and normalization\n",
    "        noise_pred = self.guide_tfm(noise_pred_neutral, noise_pred_positive, next(g_idxs))\n",
    "\n",
    "        return noise_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class KDiffusionSampler(ImageSampler, ABC):\n",
    "    sampler_func: callable\n",
    "\n",
    "    def __init__(self, model, model_name, beta_schedule='linear', \n",
    "                 beta_min=0.00085, beta_max=0.012, num_train_steps=1000):\n",
    "        super().__init__(model)\n",
    "        \n",
    "        # compute the alpha cumprods\n",
    "        if beta_schedule == 'linear':\n",
    "            betas = torch.linspace(beta_min, beta_max, num_train_timesteps, dtype=torch.float32)\n",
    "            alphas = 1.0 - betas\n",
    "            alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "            \n",
    "        model = ModelWrapper(model, alphas_cumprod)\n",
    "        \n",
    "        # wrap the model in the denoiser class\n",
    "        denoiseer_cls = (\n",
    "            WrappedCompVisVDenoiser\n",
    "            # TODO: better handling for model names\n",
    "            if model_name.split('/')[-1] in ('stable-diffusion-2', 'stable-diffusion-2-1')\n",
    "            else WrappedCompVisDenoiser\n",
    "        )\n",
    "        self.cv_denoiser = denoiseer_cls(model)\n",
    "\n",
    "    def sample(\n",
    "        self,\n",
    "        num_steps,\n",
    "        shape,\n",
    "        neutral_conditioning,\n",
    "        positive_conditioning,\n",
    "        batch_size=1,\n",
    "        mask=None,\n",
    "        orig_latent=None,\n",
    "        initial_latent=None,\n",
    "        t_start=None,\n",
    "        guide_tfm=None,\n",
    "        use_karras_sigmas=True,\n",
    "    ):\n",
    "\n",
    "        if initial_latent is None:\n",
    "            initial_latent = torch.randn(shape, device=\"cpu\").to(self.device)\n",
    "\n",
    "        #log_latent(initial_latent, \"initial_latent\")\n",
    "        if t_start is not None:\n",
    "            t_start = num_steps - t_start + 1\n",
    "        \n",
    "        if use_karras_sigmas:\n",
    "            print(f'Using Karras sigma schedule')\n",
    "            sigmas = k_sampling.get_sigmas_karras(n=num_steps, sigma_min=0.1, sigma_max=10, device=self.device)\n",
    "        else:\n",
    "            sigmas = self.cv_denoiser.get_sigmas(num_steps)[t_start:]\n",
    "        \n",
    "        # build timestep iterator for schedules\n",
    "        g_idxs = []\n",
    "        for i in range(len(sigmas)):\n",
    "            if 'sde' or '2s_a' or 'dpm_2' in self.short_name:\n",
    "                g_idxs.extend([i,i])\n",
    "            else:\n",
    "                g_idxs.append(i)\n",
    "        g_idxs = iter(g_idxs)\n",
    "\n",
    "        # if our number of steps is zero, just return the initial latent\n",
    "        if sigmas.nelement() == 0:\n",
    "            if orig_latent is not None:\n",
    "                return orig_latent\n",
    "            return initial_latent\n",
    "\n",
    "        x = initial_latent * sigmas[0]\n",
    "        #log_latent(x, \"initial_sigma_noised_tensor\")\n",
    "        model_wrap_cfg = CFGDenoiser(self.cv_denoiser, guide_tfm=guide_tfm)\n",
    "\n",
    "        mask_noise = None\n",
    "        if mask is not None:\n",
    "            mask_noise = torch.randn_like(initial_latent, device=\"cpu\").to(\n",
    "                initial_latent.device\n",
    "            )\n",
    "\n",
    "        samples = self.sampler_func(\n",
    "            model=model_wrap_cfg,\n",
    "            x=x,\n",
    "            sigmas=sigmas,\n",
    "            extra_args={\n",
    "                \"cond\": positive_conditioning,\n",
    "                \"uncond\": neutral_conditioning,\n",
    "                \"mask\": mask,\n",
    "                \"mask_noise\": mask_noise,\n",
    "                \"orig_latent\": orig_latent,\n",
    "                \"g_idxs\": g_idxs,\n",
    "            },\n",
    "            disable=False,\n",
    "            #callback=callback,\n",
    "        )\n",
    "\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the helper schedule classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def sample_dpm_adaptive(\n",
    "    model, x, sigmas, extra_args=None, disable=False, callback=None\n",
    "):\n",
    "    sigma_min = sigmas[-2]\n",
    "    sigma_max = sigmas[0]\n",
    "    return k_sampling.sample_dpm_adaptive(\n",
    "        model=model,\n",
    "        x=x,\n",
    "        sigma_min=sigma_min,\n",
    "        sigma_max=sigma_max,\n",
    "        extra_args=extra_args,\n",
    "        disable=disable,\n",
    "        callback=callback,\n",
    "    )\n",
    "\n",
    "\n",
    "def sample_dpm_fast(model, x, sigmas, extra_args=None, disable=False, callback=None):\n",
    "    sigma_min = sigmas[-2]\n",
    "    sigma_max = sigmas[0]\n",
    "    return k_sampling.sample_dpm_fast(\n",
    "        model=model,\n",
    "        x=x,\n",
    "        sigma_min=sigma_min,\n",
    "        sigma_max=sigma_max,\n",
    "        n=len(sigmas),\n",
    "        extra_args=extra_args,\n",
    "        disable=disable,\n",
    "        callback=callback,\n",
    "    )\n",
    "\n",
    "class DPMFastSampler(KDiffusionSampler):\n",
    "    short_name = KDiffusionNames.K_DPM_FAST\n",
    "    name = \"Diffusion probabilistic models - fast\"\n",
    "    default_steps = 15\n",
    "    sampler_func = staticmethod(sample_dpm_fast)\n",
    "\n",
    "\n",
    "class DPMAdaptiveSampler(KDiffusionSampler):\n",
    "    short_name = KDiffusionNames.K_DPM_ADAPTIVE\n",
    "    name = \"Diffusion probabilistic models - adaptive\"\n",
    "    default_steps = 40\n",
    "    sampler_func = staticmethod(sample_dpm_adaptive)\n",
    "\n",
    "\n",
    "class DPM2Sampler(KDiffusionSampler):\n",
    "    short_name = KDiffusionNames.K_DPM_2\n",
    "    name = \"Diffusion probabilistic models - 2\"\n",
    "    default_steps = 40\n",
    "    sampler_func = staticmethod(k_sampling.sample_dpm_2)\n",
    "\n",
    "\n",
    "class DPM2AncestralSampler(KDiffusionSampler):\n",
    "    short_name = KDiffusionNames.K_DPM_2_ANCESTRAL\n",
    "    name = \"Diffusion probabilistic models - 2 ancestral\"\n",
    "    default_steps = 40\n",
    "    sampler_func = staticmethod(k_sampling.sample_dpm_2_ancestral)\n",
    "\n",
    "\n",
    "class DPMPP2MSampler(KDiffusionSampler):\n",
    "    short_name = KDiffusionNames.K_DPMPP_2M\n",
    "    name = \"Diffusion probabilistic models - 2m\"\n",
    "    default_steps = 15\n",
    "    sampler_func = staticmethod(k_sampling.sample_dpmpp_2m)\n",
    "    \n",
    "    \n",
    "class DPMPPSDESampler(KDiffusionSampler):\n",
    "    short_name = KDiffusionNames.K_DPMPP_SDE\n",
    "    name = \"Diffusion probabilistic models - 2m\"\n",
    "    default_steps = 30\n",
    "    sampler_func = staticmethod(k_sampling.sample_dpmpp_sde)\n",
    "\n",
    "\n",
    "class DPMPP2SAncestralSampler(KDiffusionSampler):\n",
    "    short_name = KDiffusionNames.K_DPMPP_2S_ANCESTRAL\n",
    "    name = \"Ancestral sampling with DPM-Solver++(2S) second-order steps.\"\n",
    "    default_steps = 15\n",
    "    sampler_func = staticmethod(k_sampling.sample_dpmpp_2s_ancestral)\n",
    "\n",
    "\n",
    "class EulerSampler(KDiffusionSampler):\n",
    "    short_name = KDiffusionNames.K_EULER\n",
    "    name = \"Algorithm 2 (Euler steps) from Karras et al. (2022)\"\n",
    "    default_steps = 40\n",
    "    sampler_func = staticmethod(k_sampling.sample_euler)\n",
    "\n",
    "\n",
    "class EulerAncestralSampler(KDiffusionSampler):\n",
    "    short_name = KDiffusionNames.K_EULER_ANCESTRAL\n",
    "    name = \"Euler ancestral\"\n",
    "    default_steps = 40\n",
    "    sampler_func = staticmethod(k_sampling.sample_euler_ancestral)\n",
    "\n",
    "\n",
    "class HeunSampler(KDiffusionSampler):\n",
    "    short_name = KDiffusionNames.K_HEUN\n",
    "    name = \"Algorithm 2 (Heun steps) from Karras et al. (2022).\"\n",
    "    default_steps = 40\n",
    "    sampler_func = staticmethod(k_sampling.sample_heun)\n",
    "\n",
    "\n",
    "class LMSSampler(KDiffusionSampler):\n",
    "    short_name = KDiffusionNames.K_LMS\n",
    "    name = \"LMS\"\n",
    "    default_steps = 40\n",
    "    sampler_func = staticmethod(k_sampling.sample_lms)\n",
    "\n",
    "    \n",
    "    \n",
    "SAMPLERS = [\n",
    "    DPMFastSampler,\n",
    "    DPMAdaptiveSampler,\n",
    "    LMSSampler,\n",
    "    DPM2Sampler,\n",
    "    DPM2AncestralSampler,\n",
    "    DPMPP2MSampler,\n",
    "    DPMPPSDESampler,\n",
    "    DPMPP2SAncestralSampler,\n",
    "    EulerSampler,\n",
    "    EulerAncestralSampler,\n",
    "    HeunSampler,\n",
    "]\n",
    "\n",
    "SAMPLER_LOOKUP = {sampler.short_name: sampler for sampler in SAMPLERS}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
